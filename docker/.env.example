UI_LANG="zh"


#######################################################################
###################                               #####################
###################          Model Setting        #####################
###################                               #####################
#######################################################################
HF_ENDPOINT=https://hf-mirror.com

### Chat model
API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LLM_MODEL="qwen3-coder-plus"
LLM_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"

# =============================================================================
# Embedding Model Configuration
# =============================================================================
# EMBEDDED_TYPE: Embedding model type, available options:
#   - default: Use built-in pyseekdb all-MiniLM-L6-v2 model (no additional config needed)
#   - ollama: Use Ollama embedding service (requires EMBEDDED_API_KEY, EMBEDDED_LLM_MODEL, EMBEDDED_LLM_BASE_URL)
#   - openai_embedding: Use OpenAI-compatible embedding API (requires EMBEDDED_API_KEY, EMBEDDED_LLM_MODEL, EMBEDDED_LLM_BASE_URL)
EMBEDDED_TYPE=default

# Vector embedding dimension (must match your embedding model's output dimension)
EMBEDDED_DIMENSION=384

# EMBEDDED_API_KEY: API key for embedding service
#   - Required for: ollama, openai_embedding
#   - Not required for: default
EMBEDDED_API_KEY=

# EMBEDDED_LLM_MODEL: Embedding model name
#   - For ollama: model name (e.g., nomic-embed-text)
#   - For openai_embedding: model name (e.g., text-embedding-3-small)
EMBEDDED_LLM_MODEL=

# EMBEDDED_LLM_BASE_URL: Base URL for embedding service
#   - For ollama: Ollama server URL (e.g., http://localhost:11434)
#   - For openai_embedding: OpenAI API base URL (e.g., https://api.openai.com/v1)
EMBEDDED_LLM_BASE_URL=


#######################################################################
###################                               #####################
###################          Database Setting     #####################
###################                               #####################
#######################################################################
# Use what kind of docker, seekdb's docker or oceanbase-ce's docker
# Options: seekdb, oceanbase
# seekdb: If REUSE_CURRENT_DB is false, download seekdb docker
# oceanbase: If REUSE_CURRENT_DB is false, download oceanbase-ce docker
DB_STORE=seekdb

# Database Setting, please change as your environment. 
# If DB_STORE is seekdb, DB_HOST must be seekdb, if DB_STORE is oceanbase, DB_HOST must be oceanbase.
DB_HOST=seekdb
DB_PORT="2881"
#if REUSE_CURRENT_DB=false and DB_STORE=seekdb, DB_USER must be root
#if REUSE_CURRENT_DB=false and DB_STORE=oceanbase, DB_USER must be root@test
DB_USER="root"
# If database use OceanBase, the DB_USER will contain tenant's name
# DB_USER="root@test"
DB_PASSWORD="root@test"
DB_NAME="test"

SEEKDB_MEMORY_LIMIT=2G
OCEANBASE_MEMORY_LIMIT=6G


#######################################################################
###################                               #####################
###################         RAG Parser Setting    #####################
###################                               #####################
#######################################################################
# Maximum chunk size for text splitting (in characters)
MAX_CHUNK_SIZE=4096

# Limit the number of documents to process (0 means no limit)
LIMIT=0

# Patterns to skip when processing documents (comma-separated, e.g., "*.log,*.tmp")
SKIP_PATTERNS=""
# Compose profiles
COMPOSE_PROFILES=${DB_STORE:-seekdb}
